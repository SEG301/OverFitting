# SEG301 - ENTERPRISE DATA CRAWLER
**Team:** OverFitting
**Milestone:** 1 (Data Acquisition)

## ğŸš€ Overview
Project nÃ y chá»©a cÃ¡c cÃ´ng cá»¥ thu tháº­p dá»¯ liá»‡u doanh nghiá»‡p Viá»‡t Nam tá»« cÃ¡c nguá»“n cÃ´ng khai.
Má»¥c tiÃªu: Thu tháº­p >1.000.000 báº£n ghi doanh nghiá»‡p (TÃªn, MST, Äá»‹a chá»‰...).

## ğŸ“‚ Structure
- `src/crawler/speed_crawler.py`: **(RECOMMENDED)** Crawler tá»‘c Ä‘á»™ cao (Requests + Multi-threading), nháº¯m vÃ o `infodoanhnghiep.com`. Tá»‘c Ä‘á»™ ~1000 docs/s.
- `src/crawler/ultimate_crawler.py`: Crawler dá»± phÃ²ng (Selenium + Undetected Chromedriver) Ä‘á»ƒ vÆ°á»£t WAF (Cloudflare) cá»§a `masothue.com`.

## ğŸ›  Installation
1. Clone repo:
```bash
git clone https://github.com/SEG301/OverFitting.git
cd SEG301-OverFitting
```

2. Setup Virtual Environment (Windows):
```powershell
python -m venv venv
.\venv\Scripts\activate
```

3. Install Dependencies:
```bash
pip install -r requirements.txt
```

## âš¡ Usage
### 1. Fast Crawling (Recommended)
Äá»ƒ thu tháº­p dá»¯ liá»‡u nhanh (Milestone 1):
```bash
python src/crawler/speed_crawler.py
```
- Dá»¯ liá»‡u sáº½ lÆ°u táº¡i: `data_member1/speed_data.jsonl`
- Tá»‘c Ä‘á»™ dá»± kiáº¿n: 1 PhÃºt ~ 50.000 records.

### 2. Deep Crawling (Use with caution)
Äá»ƒ thu tháº­p dá»¯ liá»‡u chi tiáº¿t tá»« nguá»“n khÃ³ (Masothue):
```bash
python src/crawler/ultimate_crawler.py
```
*(LÆ°u Ã½: Chá»‰ cháº¡y 1 worker Ä‘á»ƒ trÃ¡nh bá»‹ khÃ³a IP)*

## ğŸ“Š Results (Milestone 1)
- **Total Records:** 2,267,000+
- **Format:** JSON Lines (.jsonl)
- **Fields:** `company_name`, `tax_code`, `address`, `source`, `url`.

---
*Developed by Team OverFitting @ 2026*
